{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Initialize an Embedding Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Initialize the Chroma DB Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma(collection_name=\"new_vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./new_chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load a document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1996.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader(path='example_data/text', glob=\"*.txt\", show_progress=True, loader_cls=TextLoader)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = [doc.page_content for doc in data]\n",
    "doc_metadata = [doc.metadata for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['This is pretty much\\nwhat\\'s happened so far.\\n\\nRoss was in love\\nwith Rachel since forever.\\n\\nEvery time he tried to tell her,\\nsomething got in the way\\n\\nIike cats, Italian guys.\\n\\nAnd finally, Chandler was,\\nlike, \"Forget about her.\"',\n",
       "  \"These were unbelievely expensive\\nand he'll grow out of them\\n\\nin 20 minutes,\\nbut I couldn't resist!\\n\\nLook at these.\"],\n",
       " [{'source': 'example_data\\\\text\\\\file_1.txt'},\n",
       "  {'source': 'example_data\\\\text\\\\file_2.txt'}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_content, doc_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split the document into chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.sentence_transformers import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "st_text_splitter = SentenceTransformersTokenTextSplitter(model_name=\"sentence-transformers/all-mpnet-base-v2\", \n",
    "                                                         chunk_size=100, \n",
    "                                                         chunk_overlap=50)\n",
    "\n",
    "st_chunks = st_text_splitter.create_documents(doc_content, doc_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents inside chunks: 2\n",
      "\n",
      "Document 1 metadata: {'source': 'example_data\\\\text\\\\file_1.txt'}\n",
      "Document 1 chunks: this is pretty much what ' s happened so far. ross was in love with rachel since forever. every time he tried to tell her, something got in the way iike cats, italian guys. and finally, chandler was, like, \" forget about her. \"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 metadata: {'source': 'example_data\\\\text\\\\file_2.txt'}\n",
      "Document 2 chunks: these were unbelievely expensive and he ' ll grow out of them in 20 minutes, but i couldn ' t resist! look at these.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of documents inside chunks:\", len(st_chunks))\n",
    "print()\n",
    "for i, chunk in enumerate(st_chunks, start=1):\n",
    "    print(f\"Document {i} metadata: {chunk.metadata}\")\n",
    "    print(f\"Document {i} chunks: {chunk.page_content}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add Chunks to ChromaDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e44775ef-e6d4-4363-935a-da991d70c097',\n",
       " '0e6c836b-fb64-4e3b-bc36-839eed9d9dff']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(st_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0e6c836b-fb64-4e3b-bc36-839eed9d9dff',\n",
       "  'e44775ef-e6d4-4363-935a-da991d70c097'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'example_data\\\\text\\\\file_2.txt'},\n",
       "  {'source': 'example_data\\\\text\\\\file_1.txt'}],\n",
       " 'documents': [\"these were unbelievely expensive and he ' ll grow out of them in 20 minutes, but i couldn ' t resist! look at these.\",\n",
       "  'this is pretty much what \\' s happened so far. ross was in love with rachel since forever. every time he tried to tell her, something got in the way iike cats, italian guys. and finally, chandler was, like, \" forget about her. \"'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<---New Vector Database is ready!--->**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Create a Retriever Object**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={'k': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Initialize a Chat Prompt Template** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Use only the following context to answer the question:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise, detailed answer based solely on the context. \n",
    "Do not include any information that is not explicitly stated in the context. \n",
    "Avoid phrases like \"according to the context\" or similar.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5: Initialize a Generator (i.e. Chat Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(\n",
    "    google_api_key=api_key,\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6: Initialize a Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7: Define a RAG Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_doc(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG Chain\n",
    "rag_chain = {\"context\": retriever | format_doc, \"question\": RunnablePassthrough()} | prompt_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 8: Invoke the Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ross is someone in love with Rachel. He has repeatedly tried to tell her, but has been thwarted by various obstacles.\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who is ross?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geminienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
